{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.transforms import Spectrogram, AmplitudeToDB\n",
    "from torch import nn\n",
    "\n",
    "# Paramètres\n",
    "fs = 16000  # Fréquence d'échantillonnage\n",
    "duration = 10  # Durée totale de l'audio en secondes\n",
    "c = 343  # Vitesse du son en m/s\n",
    "\n",
    "# Distance entre les microphones\n",
    "distance_between_mics = 2  # Distance \n",
    "\n",
    "# Simuler deux sources sonores\n",
    "source1_freq = 5000  # Fréquence de la première personne (en Hz)\n",
    "source2_freq = 1500  # Fréquence de la deuxième personne (en Hz)\n",
    "\n",
    "# Générer le signal de bruit ambiant avec amplitude réduite\n",
    "noise = torch.normal(mean=0, std=0.1, size=(duration * fs,))\n",
    "# Générer les signaux pour les deux sources pendant 2 secondes (de 4 à 6 secondes)\n",
    "t_source = torch.linspace(0, 4, 4 * fs)\n",
    "source1 = torch.sin(2 * np.pi * source1_freq * t_source)\n",
    "source2 = torch.sin(2 * np.pi * source2_freq * t_source)\n",
    "\n",
    "# Insérer les signaux des sources dans le bruit ambiant\n",
    "signal = noise.clone()\n",
    "signal[2*fs:6*fs] += source1\n",
    "signal[2*fs:6*fs] += source2\n",
    "\n",
    "# Ajouter des délais pour simuler l'arrivée des sons aux microphones\n",
    "delay1 = distance_between_mics / c  # Délai en secondes pour la première source\n",
    "delay_samples1 = int(delay1 * fs)  # Conversion du délai en nombre d'échantillons\n",
    "delay2 = 3 * distance_between_mics / c  # Délai pour la deuxième source\n",
    "delay_samples2 = int(delay2 * fs)\n",
    "\n",
    "# Générer les signaux capturés par chaque microphone\n",
    "mic1 = signal \n",
    "mic2 = torch.roll(signal, shifts=delay_samples1) + signal\n",
    "mic3 = torch.roll(signal, shifts=delay_samples2) + torch.roll(signal, shifts=delay_samples2)\n",
    "# Calculer les spectrogrammes complexes avec PyTorch\n",
    "transform = Spectrogram(n_fft=128, hop_length=64, power=None)\n",
    "spec1 = transform(mic1.unsqueeze(0))\n",
    "spec2 = transform(mic2.unsqueeze(0))\n",
    "spec3 = transform(mic3.unsqueeze(0))\n",
    "\n",
    "# Calcul du Logarithm Power Spectrum (LPS)\n",
    "amplitude_to_db = AmplitudeToDB()\n",
    "lps1 = amplitude_to_db(spec1.abs())\n",
    "lps2 = amplitude_to_db(spec2.abs())\n",
    "lps3 = amplitude_to_db(spec3.abs())\n",
    "\n",
    "\n",
    "# Obtenir les temps et les fréquences\n",
    "times = np.linspace(0, duration, spec1.size(-1))\n",
    "frequencies = torch.linspace(0, fs // 2, spec1.size(-2))\n",
    "\n",
    "# Tracer les spectrogrammes d'amplitude et de phase\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t_source.numpy(), mic1[2*fs:6*fs].numpy())\n",
    "plt.title('Signal reçu par le microphone 1')\n",
    "plt.xlabel('Temps [sec]')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(t_source.numpy(), mic2[2*fs:6*fs].numpy())\n",
    "plt.title('Signal reçu par le microphone 2')\n",
    "plt.xlabel('Temps [sec]')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(t_source.numpy(), mic3[2*fs:6*fs].numpy())\n",
    "plt.title('Signal reçu par le microphone 3')\n",
    "plt.xlabel('Temps [sec]')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.pcolormesh(times, frequencies, lps1[0].numpy(), shading='gouraud')\n",
    "plt.title('Spectrogramme d\\'Amplitude - Microphone 1')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Amplitude [dB]')\n",
    "\n",
    "print(times.shape)\n",
    "print(frequencies.numpy().shape)\n",
    "print(lps1[0].numpy().shape)\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.pcolormesh(times, frequencies, lps2[0].numpy(), shading='gouraud')\n",
    "plt.title('Spectrogramme d\\'Amplitude - Microphone 2')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Amplitude [dB]')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.pcolormesh(times, frequencies, lps3[0].numpy(), shading='gouraud')\n",
    "plt.title('Spectrogramme d\\'Amplitude - Microphone 3')\n",
    "plt.xlabel('Temps [sec]')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Amplitude [dB]')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.pcolormesh(times, frequencies, torch.angle(spec1[0]).numpy(), shading='gouraud')\n",
    "plt.title('Spectrogramme de Phase - Microphone 1')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Phase [radians]')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.pcolormesh(times, frequencies, torch.angle(spec2[0]).numpy(), shading='gouraud')\n",
    "plt.title('Spectrogramme de Phase - Microphone 2')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Phase [radians]')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.pcolormesh(times, frequencies, torch.angle(spec3[0]).numpy(), shading='gouraud')\n",
    "plt.title('Spectrogramme de Phase - Microphone 3')\n",
    "plt.xlabel('Temps [sec]')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Phase [radians]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer l'Inter-Channel Phase Difference (IPD) pour les paires de microphones\n",
    "ipd12 = torch.angle(spec1) - torch.angle(spec2)\n",
    "ipd13 = torch.angle(spec1) - torch.angle(spec3)\n",
    "ipd23 = torch.angle(spec2) - torch.angle(spec3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tracer les IPD\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.pcolormesh(times, frequencies, ipd12[0].numpy(), shading='gouraud')\n",
    "plt.title('IPD - Microphone 1 et 2')\n",
    "plt.xlabel('Temps [sec]')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Phase [radians]')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.pcolormesh(times, frequencies, ipd13[0].numpy(), shading='gouraud')\n",
    "plt.title('IPD - Microphone 1 et 3')\n",
    "plt.xlabel('Temps [sec]')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Phase [radians]')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.pcolormesh(times, frequencies, ipd23[0].numpy(), shading='gouraud')\n",
    "plt.title('IPD - Microphone 2 et 3')\n",
    "plt.xlabel('Temps [sec]')\n",
    "plt.ylabel('Fréquence [Hz]')\n",
    "plt.colorbar(label='Phase [radians]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calcul de l'Angle Feature (AF)\n",
    "def compute_af(theta, frequencies, distance_between_mics, c):\n",
    "    delta_m = distance_between_mics\n",
    "    v_m_theta = 2 * np.pi * frequencies * delta_m * np.cos(theta) / c\n",
    "    return v_m_theta\n",
    "\n",
    "# Directions spécifiées {0, 0.5π, π, 1.5π}\n",
    "theta_values = [0, 0.5 * np.pi, np.pi, 1.5 * np.pi]\n",
    "\n",
    "\n",
    "\n",
    "# Redimensionner les fréquences pour correspondre aux dimensions des IPD\n",
    "frequencies = torch.linspace(0, fs // 2, spec1.size(-2)).unsqueeze(-1)\n",
    "\n",
    "# Calculer et tracer les AFθ pour chaque direction\n",
    "plt.figure(figsize=(12, 16))\n",
    "\n",
    "for i, theta in enumerate(theta_values):\n",
    "    v_m_theta = compute_af(theta, frequencies, distance_between_mics, c).reshape(1, -1, 1)\n",
    "    af1 = torch.cos(v_m_theta - ipd12)\n",
    "    af2 = torch.cos(v_m_theta - ipd13)\n",
    "    af3 = torch.cos(v_m_theta - ipd23)\n",
    "\n",
    "    plt.subplot(4, 3, 3*i + 1)\n",
    "    plt.pcolormesh(np.arange(spec1.size(-1)), frequencies.squeeze(), af1[0].numpy(), shading='gouraud')\n",
    "    plt.title(f'AFθ - Microphone 1 et 2 - θ={theta} rad')\n",
    "    plt.ylabel('Fréquence [Hz]')\n",
    "    plt.colorbar(label='Amplitude')\n",
    "\n",
    "    plt.subplot(4, 3, 3*i + 2)\n",
    "    plt.pcolormesh(np.arange(spec2.size(-1)), frequencies.squeeze(), af2[0].numpy(), shading='gouraud')\n",
    "    plt.title(f'AFθ - Microphone 1 et 3 - θ={theta} rad')\n",
    "    plt.ylabel('Fréquence [Hz]')\n",
    "    plt.colorbar(label='Amplitude')\n",
    "\n",
    "    plt.subplot(4, 3, 3*i + 3)\n",
    "    plt.pcolormesh(np.arange(spec3.size(-1)), frequencies.squeeze(), af3[0].numpy(), shading='gouraud')\n",
    "    plt.title(f'AFθ - Microphone 2 et 3 - θ={theta} rad')\n",
    "    plt.xlabel('Temps [sec]')\n",
    "    plt.ylabel('Fréquence [Hz]')\n",
    "    plt.colorbar(label='Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
